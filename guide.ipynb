{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide: How to Train a ProSoRo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a guide for training a proprioceptive soft robot (ProSoRo). The ProSoRo's proprioception ability is based on a multimodal variational autoencoder (MVAE) trained with finite element analysis (FEA) data, which includes the shape reconstruction and force estimation. In the following sections, we will set up the environment, prepare the Abaqus simulation dataset, train the MVAE, and finally test the performance of the ProSoRo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, you should ensure that you have installed `pytorch>=2.1`, and `abaqus>=2022`. \n",
    "\n",
    "Then install the required packages by running the following command:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input File Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.inp` file is necessary for Abaqus simulation. It contains the information about the geometry, material properties, boundary conditions, history and field outputs, etc. Here we provide typical steps to create an `.inp` file, taking a cylinder as an example. If you don't want to create the `.inp` file yourself, just use the provided `template.inp` in the `./templates/cylinder/` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After opening the Abaqus CAE, we create a new model database with standard/explicit model. Then a new part should be created by either creating a new `Part` or importing a geometry file. Here we create a new part by selecting `Part` -> `Create` -> `3D` -> `Deformable` -> `Solid` -> `Extrusion` -> `Continue`. Then we create a circle with a radius of 20, and exit the sketch by clicking `Done`. After that, we extrude the circle with a depth of 40 by clicking `OK`. Now we have a cylinder part. It's optional to add some wires on the surface in order to make the mesh finer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![part.jpg](./assets/img/abaqus/part.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `Property` module, we create a new `Material`, select the material behavior, and input the corresponding parameters. Here we select `Mechanical` -> `Elasticity` -> `Elastic`, and input `Young's modulus=0.2` and `Poisson's ratio=0.4`. Then we create a new `Section` with `Solid` -> `Homogeneous` type, select the `Material` we just created. After that, we need to assign the `Section` to the part by selecting the part and clicking `Assign Section`. Now the material properties are defined, and the color of the part becomes green."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![property.jpg](./assets/img/abaqus/property.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `Assembly` module, we add the part to the assembly by selecting `Instance` -> `Create` -> `Part` -> `OK`. Note that we set `Instance Type` as `Dependent (mesh on part)`. The axis origin is at the center of the bottom surface of the cylinder, which is convenient for the following steps. And now we need to define sets, reference points, and surfaces, which can be found in the `Tools`:\n",
    "\n",
    "- `RP-1`: create a reference point at the center of the top surface.\n",
    "- `Set-RP-1`: create a set and select the reference point `RP-1`.\n",
    "- `Set-bottom_surface`: create a set and select the bottom surface of the cylinder.\n",
    "- `Set-top_surface`: create a set and select the top surface of the cylinder.\n",
    "- `Set-surface`: create a set and select all surfaces of the cylinder.\n",
    "- `Surf-bottom_surface`: create a surface and select the bottom surface of the cylinder.\n",
    "- `Surf-top_surface`: create a surface and select the top surface of the cylinder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![assembly.jpg](./assets/img/abaqus/assembly.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `Step` module, we create a new `Step` with `Static, General` type, and set `Nlgeom` as `On`. Then we need to edit the `Field Output` and select `S, U` as the output variables. For the `History Output`, the domain needs to be selected as `Integrated output section` which needs to be created with `Surf-bottom_surface`, and the output variables are `SOF, SOM`. Since we mainly consider the geometry and force information, other output variables can be ignored. If you are interested in other variables, you can add them as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![step.jpg](./assets/img/abaqus/step.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `Interaction` module, we need to define the constraints between `RP-1` and `Surf-top_surface`. `Coupling` type `Constraint` is created with `Set-RP-1` selected as `Control points` and `Surf-top_surface` selected as `Surface`. The `Coupling type` is set as `Kinematic`, and the `Constrained degrees of freedom` are set as all. Now we are able to move the `Surf-top_surface` by changing the position of `RP-1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![interaction.jpg](./assets/img/abaqus/interaction.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `Load` module, we first create a `BC-1` with `Symmetry/Antisymmetry/Encastre` type at `Initial` step, and select `Set-bottom_surface` as the `Region` and `ENCASTRE` as the `Boundary condition`. Then we create a `BC-2` with `Displacement/Rotation` type at `Step-1` step, and select `Set-RP-1` as the `Region` and all degrees of freedom with `0` or other values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![load.jpg](./assets/img/abaqus/load.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `Mesh` module, we need to first select the `Mesh controls` and set the `Element shape` as `Tet`. Then we need to make the element type as `C3D4` by selecting `Mesh` -> `Element type` and changing the `Geometric Order` as `Linear`, and the color of the geometry becomes pink. It's optional to refine the mesh by selecting `Seed part` and setting the `Approximate global size`, `Maximum deviation factor`, and `Minimum size`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mesh.jpg](./assets/img/abaqus/mesh.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all above steps, we create the job to generate the `.inp` file. We can select `Create` in `Job manager`, and click the `Data Check` to check whether there are any errors. If there is no error, we can click `Write input` to generate the `.inp` file. The `.inp` file will be saved in the working directory, which is going to be used in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![job.jpg](./assets/img/abaqus/job.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some necessary packages and functions needed to be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from typing import List\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from pytorch_lightning import LightningModule\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to generate motion data of the `RP-1` in the `.inp` file. First, we need to define serveral settings:\n",
    "\n",
    "- `object`: the type of the target module object, which is `cylinder` in this example.\n",
    "- `data_path`: the path to save the motion data, typically based on the `object`.\n",
    "- `data_num`: the number of motion data to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module type\n",
    "object = \"cylinder\"\n",
    "# Data path\n",
    "data_path = \"./data/\" + object + \"/\"\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "# Data number\n",
    "data_num = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can generate the motion, including `u1`, `u2`, `u3`, `r1`, `r2`, `r3`. Each component is randomly generated within a certain range. You can adjust the range based on your requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate motion.csv\n",
    "csv_file = open(data_path + \"motion.csv\", \"w\", encoding=\"utf-8\", newline=\"\")\n",
    "csv_writer = csv.writer(csv_file)\n",
    "count = 0\n",
    "while count < data_num:\n",
    "    u1 = random.uniform(-8, 8)\n",
    "    u2 = random.uniform(-8, 8)\n",
    "    u3 = random.uniform(-3, 3)\n",
    "    ur1 = random.uniform(0, 0.3) * (1 if u2 < 0 else -1)\n",
    "    ur2 = random.uniform(0, 0.3) * (1 if u1 > 0 else -1)\n",
    "    ur3 = random.uniform(-0.3, 0.3)\n",
    "    count += 1\n",
    "    csv_writer.writerow(\n",
    "        [\n",
    "            count,\n",
    "            np.around(u1, 3),\n",
    "            np.around(u2, 3),\n",
    "            np.around(u3, 3),\n",
    "            np.around(ur1, 2),\n",
    "            np.around(ur2, 2),\n",
    "            np.around(ur3, 2),\n",
    "        ]\n",
    "    )\n",
    "csv_file.close()\n",
    "print(\"Motion.csv has been generated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating the motion, we can visualize the data points in the 3D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize motion.csv\n",
    "csv_file = open(data_path + \"motion.csv\", \"r\", encoding=\"utf-8\")\n",
    "csv_reader = csv.reader(csv_file)\n",
    "motion = []\n",
    "for item in csv_reader:\n",
    "    motion.append(item)\n",
    "csv_file.close()\n",
    "motion = np.array(motion[1:]).astype(np.float32)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.scatter(motion[:, 1], motion[:, 2], motion[:, 3], c=\"r\", marker=\"o\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input File Generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to change some configurations in the `.inp` file to make it as a template. We just replace the `BC-2` settings with the following text:\n",
    "\n",
    "``` text\n",
    "** Name: BC_2 Type: Displacement/Rotation\n",
    "*Boundary\n",
    "Set-RP-1, 1, 1, u1\n",
    "Set-RP-1, 2, 2, u2\n",
    "Set-RP-1, 3, 3, u3\n",
    "Set-RP-1, 4, 4, ur1\n",
    "Set-RP-1, 5, 5, ur2\n",
    "Set-RP-1, 6, 6, ur3\n",
    "```\n",
    "\n",
    "and also rename the file as `template.inp`, and move it to `./templates/cylinder/`.\n",
    "\n",
    "To faster the simulation, we can seperate the simulation into multiple parts and run them in parallel. Here we set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_num = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then `.inp` files will be generated into folders. Now just run the following cell to complete the `.inp` file generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read template.inp\n",
    "temp_file = open(\"./templates/\" + object + \"/template.inp\", \"r\")\n",
    "temp_lines = temp_file.read()\n",
    "temp_file.close()\n",
    "\n",
    "# Read motion.csv file\n",
    "motion_list = pd.read_csv(data_path + \"motion.csv\", header=None)\n",
    "# Seperate motion_list\n",
    "for i in range(part_num):\n",
    "    motion_list.iloc[\n",
    "        int(len(motion_list) / part_num * i) : int(len(motion_list) / part_num * (i + 1))\n",
    "    ].to_csv(data_path + \"motion_\" + str(i + 1) + \".csv\", header=None, index=None)\n",
    "\n",
    "for i in range(1, part_num + 1):\n",
    "    # Read motion_*.csv file\n",
    "    motion_csv_name = data_path + \"motion_\" + str(i) + \".csv\"\n",
    "    motion_csv_file = open(motion_csv_name, \"r\", encoding=\"utf-8\")\n",
    "    motion_csv_reader = csv.reader(motion_csv_file)\n",
    "\n",
    "    # Create folder to store *.inp files\n",
    "    inp_path = \"data/\" + object + \"/abq_file_\" + str(i) + \"/\"\n",
    "    if not os.path.exists(inp_path):\n",
    "        os.makedirs(inp_path)\n",
    "\n",
    "    # Write *.inp files\n",
    "    for motion in motion_csv_reader:\n",
    "        inp_lines = temp_lines\n",
    "        inp_lines = (\n",
    "            inp_lines.replace(\"u1\", motion[1])\n",
    "            .replace(\"u2\", motion[2])\n",
    "            .replace(\"u3\", motion[3])\n",
    "            .replace(\"ur1\", motion[4])\n",
    "            .replace(\"ur2\", motion[5])\n",
    "            .replace(\"ur3\", motion[6])\n",
    "        )\n",
    "        inp_file = open(inp_path + motion[0] + \".inp\", \"w\")\n",
    "        inp_file.write(inp_lines)\n",
    "        inp_file.close()\n",
    "\n",
    "    motion_csv_file.close()\n",
    "    os.remove(motion_csv_name)\n",
    "\n",
    "print(\"All *.inp files have been written successfully.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Ubuntu (Linux), you can use the following command in `Terminal` to submit a single job:\n",
    "\n",
    "```bash\n",
    "abq job={JOB_NAME} cpus=4 int\n",
    "```\n",
    "\n",
    "To submit multiple jobs in batch, you first need a `.sh` file with the following content:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "pasway=`dirname $0`\n",
    "pushd $pasway\n",
    "echo $basename\n",
    "for file in `ls $pasway/*.inp`;\n",
    "do\n",
    "abq job=`basename $file` cpus=4 int;\n",
    "done\n",
    "echo all finished\n",
    "read -n 1\n",
    "```\n",
    "\n",
    "The `.sh` file is already prepared in `./scripts/cmd/` folder. You can run the following command to copy the `.sh` file to the folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, part_num + 1):\n",
    "    src_file = \"./scripts/cmd/run.sh\"\n",
    "    dst_file = \"./data/\" + object + \"/abq_file_\" + str(i) + \"/run.sh\"\n",
    "    shutil.copy(src_file, dst_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can open `Terminal` in each `abq_file_{PART_NUM}` folder and run the following command to start the simulation:\n",
    "\n",
    "```bash\n",
    "cd data/cylinder/abq_file_{PART_NUM}\n",
    "sudo chmod +x run.sh\n",
    "sh run.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For windows, you can use the following command in `PowerShell` to submit a single job:\n",
    "\n",
    "```bash\n",
    "abaqus job={JOB_NAME} cpus=4 int\n",
    "```\n",
    "\n",
    "To submit multiple jobs in batch, you first need a `.bat` file with the following content:\n",
    "\n",
    "```bat\n",
    "@echo off\n",
    "for /f \"delims=\" %%i in ('dir /b *.inp') do (\n",
    "abaqus job=%%i cpus=4 int\n",
    ")\n",
    "```\n",
    "\n",
    "The `.bat` file is already prepared in `./scripts/cmd/` folder. You can run the following command to copy the `.bat` file to the folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, part_num + 1):\n",
    "    src_file = \"./scripts/cmd/run.bat\"\n",
    "    dst_file = \"./data/\" + object + \"/abq_file_\" + str(i) + \"/run.bat\"\n",
    "    shutil.copy(src_file, dst_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can open `PowerShell` in each `abq_file_{PART_NUM}` folder and run the following command to start the simulation:\n",
    "\n",
    "```bash\n",
    "cd data\\cylinder\\abq_file_{PART_NUM}\n",
    "run.bat\n",
    "```\n",
    "\n",
    "It will take some time to finish the simulation, so please be patient. All files generated during the simulation will be saved in the `data/cylinder/abq_file/` folder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finishing all the simulations, we need to collect data from `.odb` files.\n",
    "\n",
    "First, we should move all files into `abq_file/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move all files to one folder\n",
    "dst_path = data_path + \"abq_file/\"\n",
    "if not os.path.exists(dst_path):\n",
    "    os.makedirs(dst_path)\n",
    "\n",
    "part_num = 10\n",
    "for i in range(1, part_num + 1):\n",
    "    src_path = data_path + \"abq_file_\" + str(i) + \"/\"\n",
    "\n",
    "    for file in os.listdir(src_path):\n",
    "        shutil.move(src_path + file, dst_path + file)\n",
    "    os.rmdir(src_path)\n",
    "\n",
    "print(\"All files have been moved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to find out which files are completed successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all .sta file names\n",
    "abq_path = \"./data/\" + object + \"/abq_file/\"\n",
    "files = os.listdir(abq_path)\n",
    "stas = []\n",
    "for file in files:\n",
    "    if file.endswith(\".sta\"):\n",
    "        stas.append(file)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Get all *.odb file names of the jobs that has completed successfully\n",
    "criteria = [\" THE ANALYSIS HAS COMPLETED SUCCESSFULLY\\n\"]\n",
    "odbs = []\n",
    "for sta in stas:\n",
    "    # Linux: 'utf-8' Windows: 'gbk'\n",
    "    last_line = open(os.path.join(abq_path, sta), \"r\", encoding=\"gbk\").readlines()[-1]\n",
    "    if last_line in criteria:\n",
    "        odbs.append(sta.replace(\"sta\", \"odb\"))\n",
    "\n",
    "csv_path = \"data/\" + object + \"/\"\n",
    "csv_file = open(\n",
    "    os.path.join(csv_path, \"cpl_odb.csv\"), \"w\", encoding=\"utf-8\", newline=\"\"\n",
    ")\n",
    "csv_writer = csv.writer(csv_file)\n",
    "for odb in odbs:\n",
    "    csv_writer.writerow([odb])\n",
    "csv_file.close()\n",
    "\n",
    "print(\n",
    "    \"All *.odb file names of the jobs that has completed successfully have been selected in cpl_odb.csv.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scirpt `read_odb.py` is provided in the `./scripts/` folder to read the `.odb` files and extract the data. We can run the following command to extract the data:\n",
    "\n",
    "```bash\n",
    "abaqus cae script=scripts/read_odb.py -- cylinder\n",
    "```\n",
    "\n",
    "The data will be saved in a new `csv_file/` folder. Now we can collect the data and save them into `.npy` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect motion, force and shape data from *.csv files\n",
    "odb_list_file = open(data_path + \"cpl_odb.csv\", \"r\")\n",
    "odb_list = csv.reader(odb_list_file, delimiter=\",\")\n",
    "motion = []\n",
    "force = []\n",
    "node = []\n",
    "for odb in odb_list:\n",
    "    csv_file = open(data_path + \"abq_file/\" + \"\".join(odb).replace(\".odb\", \".csv\"), \"r\")\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    node_rows = []\n",
    "    for i, rows in enumerate(csv_reader):\n",
    "        if i == 0:\n",
    "            motion.append(rows[1:])\n",
    "        if i == 1:\n",
    "            force.append(rows)\n",
    "        if i >= 2:\n",
    "            node_rows.append(rows)\n",
    "    node.append(np.array(node_rows, dtype=float))\n",
    "    csv_file.close()\n",
    "odb_list_file.close()\n",
    "\n",
    "# Save data as npy file\n",
    "node = np.array(node, dtype=float)\n",
    "print(\"Shape of node:\", node.shape)\n",
    "motion = np.array(motion, dtype=float)\n",
    "print(\"Shape of motion:\", motion.shape)\n",
    "force = np.array(force, dtype=float)\n",
    "print(\"Shape of force:\", force.shape)\n",
    "data = np.concatenate(\n",
    "    (\n",
    "        motion,\n",
    "        force,\n",
    "        node[:, :, 1:].reshape(node.shape[0], node.shape[1] * (node.shape[2] - 1)),\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "print(\"Shape of data:\", data.shape)\n",
    "np.save(data_path + \"data.npy\", data)\n",
    "\n",
    "print(\"The npy files have been written successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have collected the data into `.npy` files. Then we seperate `data.npy` into `train.npy` and `test.npy` with a ratio of 0.8:0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly seperate data into training data and testing data\n",
    "data = np.load(data_path + \"data.npy\")\n",
    "np.random.shuffle(data)\n",
    "training_data = data[: int(len(data) * 0.8)]\n",
    "np.save(data_path + \"training_data.npy\", training_data)\n",
    "print(\"Shape of training Data:\", training_data.shape)\n",
    "testing_data = data[int(len(data) * 0.8) :]\n",
    "np.save(data_path + \"testing_data.npy\", testing_data)\n",
    "print(\"Shape of testing data:\", testing_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have successfully prepared the dataset for training and testing the MVAE model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to train the MVAE model with the dataset we prepared in the previous section. `train.py` is the script to train and there are several arguments you can set:\n",
    "\n",
    "- `--lr`: the learning rate of the optimizer, which is `1e-5` in this example.\n",
    "- `--batch-size`: the batch size of the training data, which is `128` in this example.\n",
    "- `--max-epochs`: the maximum epoch of the training process, which is `1000` in this example.\n",
    "\n",
    "Moreover, there are some parameters for the MVAE model defined in `./config/model.yaml`:\n",
    "\n",
    "- `object`: the type of the target object, which is `cylinder` in this example.\n",
    "- `x_dim`: the dimension list of input data x, which is `[6, 6, 2148]` for the cylinder in this example.\n",
    "- `z_dim`: the dimension of the latent variable, which is `32` in this example.\n",
    "- `h1_dim`: the dimension list of the first hidden layer, which is `[16, 16, 1024]` in this example.\n",
    "- `h2_dim`: the dimension list of the second hidden layer, which is `[32, 32, 256]` in this example.\n",
    "- `recon_pred_scale`: the scale of reconstruction and prediction loss.\n",
    "- `z_coef`: the coefficient of the latent loss.\n",
    "- `kl_coef`: the coefficient of the KL divergence.\n",
    "\n",
    "You can set these parameters based on your requirements in the `train.py` script, and then run the following command to start the training process:\n",
    "\n",
    "```bash\n",
    "python train.py\n",
    "```\n",
    "\n",
    "The training is based on PyTorch Lightning, which will save the logs in `./lightning_logs/`. The `.pth` file will be saved in `model/pths/`, and named as `mvae_{object}_{recon_pred_scale}_{z_coef}_{kl_coef}_{z_dim}.pth`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, you can test the performance of the MVAE model with the test dataset. First, we need to load the trained model and the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class MVAE(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_dim: list = [6, 6, 2136],\n",
    "        h1_dim: list = [8, 8, 512],\n",
    "        h2_dim: list = [16, 16, 128],\n",
    "        z_dim: int = 32,\n",
    "        lr: float = 1e-4,\n",
    "        recon_pred_scale: float = 1,\n",
    "        z_coef: float = 1,\n",
    "        kl_coef: float = 1,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        # Call the super constructor\n",
    "        super().__init__()\n",
    "\n",
    "        # Save hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = lr\n",
    "        self.z_dim = z_dim\n",
    "        self.x_dim = x_dim\n",
    "        self.h1_dim = h1_dim\n",
    "        self.h2_dim = h2_dim\n",
    "        self.recon_pred_scale = recon_pred_scale\n",
    "        self.z_coef = z_coef\n",
    "        self.kl_coef = kl_coef\n",
    "\n",
    "        # Define the model architecture\n",
    "        for i in range(len(self.x_dim)):\n",
    "            # Encoder\n",
    "            setattr(\n",
    "                self,\n",
    "                f\"encoder_{i}\",\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(self.x_dim[i], self.h1_dim[i]),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(self.h1_dim[i], self.h2_dim[i]),\n",
    "                ),\n",
    "            )\n",
    "            # Decoder\n",
    "            setattr(\n",
    "                self,\n",
    "                f\"decoder_{i}\",\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(self.z_dim, self.h2_dim[i]),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(self.h2_dim[i], self.h1_dim[i]),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(self.h1_dim[i], self.x_dim[i]),\n",
    "                ),\n",
    "            )\n",
    "            # mu and var\n",
    "            setattr(self, f\"fc_mu_{i}\", nn.Linear(self.h2_dim[i], self.z_dim))\n",
    "            setattr(self, f\"fc_var_{i}\", nn.Linear(self.h2_dim[i], self.z_dim))\n",
    "\n",
    "    def sample(self, mu: Tensor, var: Tensor):\n",
    "        # Calculate the p and q\n",
    "        std = torch.exp(var / 2)\n",
    "        p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "\n",
    "        # Sample the z\n",
    "        z = q.rsample()\n",
    "\n",
    "        # Return the output data\n",
    "        return p, q, z\n",
    "\n",
    "    def x_to_z_encoder(self, x: Tensor, input_index: int):\n",
    "        \"\"\"Encoder from x to z.\n",
    "\n",
    "        Args:\n",
    "            x: the input data.\n",
    "            input_index: the index of the input data.\n",
    "\n",
    "        Returns:\n",
    "            z: the z.\n",
    "        \"\"\"\n",
    "\n",
    "        # Encoder with index\n",
    "        h = getattr(self, f\"encoder_{input_index}\")(x)\n",
    "        # mu and var with index\n",
    "        mu = getattr(self, f\"fc_mu_{input_index}\")(h)\n",
    "        var = getattr(self, f\"fc_var_{input_index}\")(h)\n",
    "        # Sample\n",
    "        _, _, z = self.sample(mu, var)\n",
    "\n",
    "        # Return z\n",
    "        return z\n",
    "\n",
    "    def z_to_x_decoder(self, z: Tensor, output_index: int):\n",
    "        \"\"\"Decoder from z to x.\n",
    "\n",
    "        Args:\n",
    "            z: the input data.\n",
    "            output_index: the index of the output data.\n",
    "\n",
    "        Returns:\n",
    "            x_hat: the output data.\n",
    "        \"\"\"\n",
    "\n",
    "        # Decoder with index\n",
    "        x_hat = getattr(self, f\"decoder_{output_index}\")(z)\n",
    "\n",
    "        # Return x_hat\n",
    "        return x_hat\n",
    "\n",
    "    def forward(self, x_list: List[Tensor]):\n",
    "        # Create the list to store the output data\n",
    "        x_hat_list = []\n",
    "\n",
    "        # Forward the model\n",
    "        for i in range(len(self.x_dim)):\n",
    "            # Encoder\n",
    "            z = self.x_to_z_encoder(x_list[i], i)\n",
    "            # Decoder\n",
    "            x_hat = self.z_to_x_decoder(z, i)\n",
    "            x_hat_list.append(x_hat)\n",
    "\n",
    "        # Return the output data\n",
    "        return x_hat_list\n",
    "\n",
    "    def forward_with_index(self, x: Tensor, input_index: int, output_index: int):\n",
    "        # Encoder with index\n",
    "        z = self.x_to_z_encoder(x, input_index)\n",
    "        # Decoder with index\n",
    "        x_hat = self.z_to_x_decoder(z, output_index)\n",
    "\n",
    "        # Return the output data\n",
    "        return x_hat\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "object = \"cylinder\"\n",
    "recon_pred_scale = 1\n",
    "z_coef = 1\n",
    "kl_coef = 0.1\n",
    "x_dim = [6, 6, 2736]\n",
    "h1_dim = [16, 16, 1024]\n",
    "h2_dim = [32, 32, 256]\n",
    "z_dim = 32\n",
    "\n",
    "# Load the model\n",
    "pth_path = (\n",
    "    \"./models/checkpoints/mvae_\"\n",
    "    + object\n",
    "    + \"_\"\n",
    "    + str(recon_pred_scale)\n",
    "    + \"_\"\n",
    "    + str(z_coef)\n",
    "    + \"_\"\n",
    "    + str(kl_coef)\n",
    "    + \"_\"\n",
    "    + str(z_dim)\n",
    "    + \".pth\"\n",
    ")\n",
    "model = MVAE(\n",
    "    x_dim=x_dim,\n",
    "    h1_dim=h1_dim,\n",
    "    h2_dim=h2_dim,\n",
    "    z_dim=z_dim,\n",
    "    recon_pred_scale=recon_pred_scale,\n",
    "    z_coef=z_coef,\n",
    "    kl_coef=kl_coef,\n",
    ")\n",
    "model.load_state_dict(torch.load(pth_path))\n",
    "model.eval()\n",
    "\n",
    "# Load the data\n",
    "data_path = \"./data/\" + object + \"/\"\n",
    "mu = np.load(data_path + \"mu.npy\")\n",
    "std = np.load(data_path + \"std.npy\")\n",
    "testing_data = np.load(data_path + \"testing_data.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test the performance of force estimation and node reconstruction based on the motion data. First, let's predict the force and node displacement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the force and node\n",
    "motion_list = testing_data[:, :6]\n",
    "force_gt_list = testing_data[:, 6:12]\n",
    "node_gt_list = testing_data[:, 12:].reshape(-1, 3)\n",
    "force_pred_list = []\n",
    "node_pred_list = []\n",
    "for i in range(len(testing_data)):\n",
    "    motion = motion_list[i]\n",
    "    motion = (motion - mu[:6]) / std[:6]\n",
    "    motion_tensor = torch.from_numpy(motion).float()\n",
    "    force_pred = model.forward_with_index(motion_tensor, 0, 1).detach().numpy()\n",
    "    force_pred = force_pred * std[6:12] + mu[6:12]\n",
    "    force_pred_list.append(force_pred)\n",
    "    node_pred = model.forward_with_index(motion_tensor, 0, 2).detach().numpy()\n",
    "    node_pred = node_pred * std[12:] + mu[12:]\n",
    "    node_pred_list.append(node_pred)\n",
    "force_pred_list = np.array(force_pred_list)\n",
    "node_pred_list = np.array(node_pred_list).reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the predicted data and ground truth, we can calculate the r.s.m.e. (root mean square error) and R2 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rmse\n",
    "force_rmse = np.sqrt(np.mean((force_gt_list[:, :3] - force_pred_list[:, :3]) ** 2))\n",
    "torque_rmse = np.sqrt(np.mean((force_gt_list[:, 3:] - force_pred_list[:, 3:]) ** 2))\n",
    "node_rmse = np.sqrt(np.mean((node_gt_list - node_pred_list) ** 2))\n",
    "print(\"Force RMSE:\", force_rmse)\n",
    "print(\"Torque RMSE:\", torque_rmse)\n",
    "print(\"Node RMSE:\", node_rmse)\n",
    "\n",
    "# Calculate r2\n",
    "force_r2 = 1 - np.sum((force_gt_list[:, :3] - force_pred_list[:, :3]) ** 2) / np.sum(\n",
    "    (force_gt_list[:, :3] - np.mean(force_gt_list[:, :3])) ** 2\n",
    ")\n",
    "torque_r2 = 1 - np.sum((force_gt_list[:, 3:] - force_pred_list[:, 3:]) ** 2) / np.sum(\n",
    "    (force_gt_list[:, 3:] - np.mean(force_gt_list[:, 3:])) ** 2\n",
    ")\n",
    "node_r2 = 1 - np.sum((node_gt_list - node_pred_list) ** 2) / np.sum(\n",
    "    (node_gt_list - np.mean(node_gt_list)) ** 2\n",
    ")\n",
    "print(\"Force R2:\", force_r2)\n",
    "print(\"Torque R2:\", torque_r2)\n",
    "print(\"Node R2:\", node_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the predicted and ground truth data to visualize the performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear plot function\n",
    "def gt_pred_plot(gt, pred, name, color):\n",
    "    subplot_num = len(gt[0])\n",
    "    fig = plt.figure(figsize=(3 * subplot_num, 3), dpi=200)\n",
    "    for i in range(subplot_num):\n",
    "        plt.subplot(1, subplot_num, i + 1)\n",
    "        plt.plot(gt[:, i], pred[:, i], \".\", color=color, markersize=\"1\")\n",
    "        plt.plot(\n",
    "            [0, 1],\n",
    "            [0, 1],\n",
    "            \"k--\",\n",
    "            linewidth=0.8,\n",
    "            alpha=0.5,\n",
    "            transform=plt.gca().transAxes,\n",
    "        )\n",
    "        plt.xlabel(\"Ground truth\")\n",
    "        plt.ylabel(\"Prediction\")\n",
    "        plt.grid()\n",
    "        plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "    fig.suptitle(name)\n",
    "    fig.tight_layout(pad=0.4, w_pad=0, h_pad=10)\n",
    "\n",
    "\n",
    "# Plot the force\n",
    "random_index = np.random.choice(len(force_gt_list), 2000)\n",
    "gt_pred_plot(\n",
    "    gt=force_gt_list[random_index, :3],\n",
    "    pred=force_pred_list[random_index, :3],\n",
    "    name=\"Force\",\n",
    "    color=\"#38bdf6\",\n",
    ")\n",
    "gt_pred_plot(\n",
    "    gt=force_gt_list[random_index, 3:],\n",
    "    pred=force_pred_list[random_index, 3:],\n",
    "    name=\"Torque\",\n",
    "    color=\"#38bdf6\",\n",
    ")\n",
    "\n",
    "# Plot the node\n",
    "random_index = np.random.choice(len(node_gt_list), 2000)\n",
    "gt_pred_plot(\n",
    "    gt=node_gt_list[random_index],\n",
    "    pred=node_pred_list[random_index],\n",
    "    name=\"Node\",\n",
    "    color=\"#38bdf6\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can imput a motion and get the predicted force with the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion = np.array([0, 0, 0, 0, 0, 0])\n",
    "print(\n",
    "    \"Motion:[%.3f, %.3f, %.3f, %.3f, %.3f, %.3f]\"\n",
    "    % (motion[0], motion[1], motion[2], motion[3], motion[4], motion[5])\n",
    ")\n",
    "motion_tensor = torch.from_numpy((motion - mu[:6]) / std[:6]).float()\n",
    "force_pred = model.forward_with_index(motion_tensor, 0, 1).detach().numpy()\n",
    "force_pred = force_pred * std[6:12] + mu[6:12]\n",
    "print(\n",
    "    \"Force:[%.3f, %.3f, %.3f, %.3f, %.3f, %.3f]\"\n",
    "    % (\n",
    "        force_pred[0],\n",
    "        force_pred[1],\n",
    "        force_pred[2],\n",
    "        force_pred[3],\n",
    "        force_pred[4],\n",
    "        force_pred[5],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also able to visualize the shape reconstruction in 3D. First, we need to prepared two files in `templates/cylinder/`:\n",
    "\n",
    "- `node.txt`: the node coordinates, copied from the `template.inp`.\n",
    "- `element.txt`: the element nodes, copied from the `template.inp`.\n",
    "\n",
    "Since the element type is `C3D4`, we can use the following code to generate triangular faces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object = \"cylinder\"\n",
    "element = np.loadtxt(\"./templates/\" + object + \"/element.txt\", delimiter=\",\")\n",
    "triangles = []\n",
    "for i in range(element.shape[0]):\n",
    "    triangles.append([element[i, 1], element[i, 2], element[i, 3]])\n",
    "    triangles.append([element[i, 1], element[i, 3], element[i, 4]])\n",
    "    triangles.append([element[i, 1], element[i, 2], element[i, 4]])\n",
    "    triangles.append([element[i, 2], element[i, 3], element[i, 4]])\n",
    "triangles = np.sort(np.array(triangles, dtype=int), axis=1)\n",
    "triangles = np.array(list(set([tuple(t) for t in triangles])), dtype=int)\n",
    "np.savetxt(\n",
    "    \"templates/\" + object + \"/triangles.txt\", triangles, delimiter=\",\", fmt=\"%7d\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to prepare the `surf_index.txt` file, which contains the surface index of the cylinder. The surface index can be copied from the `template.inp` file, and saved as `surf_index.txt` in the `templates/cylinder/` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We mainly consider the surface nodes, so we can filter the nodes and triangles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = np.loadtxt(\"./templates/\" + object + \"/node.txt\", delimiter=\",\")\n",
    "surf_index = np.loadtxt(\n",
    "    \"./templates/\" + object + \"/surf_index.txt\", delimiter=\",\"\n",
    ").astype(int)\n",
    "surf_node = []\n",
    "for i in range(node.shape[0]):\n",
    "    if node[i, 0] in surf_index:\n",
    "        surf_node.append(node[i])\n",
    "surf_node = np.array(surf_node)\n",
    "np.savetxt(\n",
    "    \"./templates/\" + object + \"/surf_node.txt\",\n",
    "    surf_node,\n",
    "    delimiter=\",\",\n",
    "    fmt=\"%7d, %12.7f, %12.7f, %12.7f\",\n",
    ")\n",
    "\n",
    "triangles = np.loadtxt(\"./templates/\" + object + \"/triangles.txt\", delimiter=\",\")\n",
    "surf_index = np.loadtxt(\n",
    "    \"./templates/\" + object + \"/surf_index.txt\", delimiter=\",\"\n",
    ").astype(int)\n",
    "surf_triangles = []\n",
    "for i in range(triangles.shape[0]):\n",
    "    if (\n",
    "        triangles[i, 0] in surf_index\n",
    "        and triangles[i, 1] in surf_index\n",
    "        and triangles[i, 2] in surf_index\n",
    "    ):\n",
    "        surf_triangles.append(triangles[i])\n",
    "surf_triangles = np.array(surf_triangles)\n",
    "for i in range(surf_triangles.shape[0]):\n",
    "    for j in range(3):\n",
    "        surf_triangles[i, j] = surf_index.tolist().index(surf_triangles[i, j])\n",
    "np.savetxt(\n",
    "    \"./templates/\" + object + \"/surf_triangles.txt\",\n",
    "    surf_triangles,\n",
    "    delimiter=\",\",\n",
    "    fmt=\"%7d, %7d, %7d\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we initialize the plotly figure and add the cylinder without deformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_pred = np.zeros_like(surf_node[:, 1:])\n",
    "node_curr = surf_node.copy()\n",
    "node_curr[:, 1:] += node_pred\n",
    "\n",
    "mesh3d = go.Mesh3d(\n",
    "    x=node_curr[:, 1],\n",
    "    y=node_curr[:, 2],\n",
    "    z=node_curr[:, 3],\n",
    "    i=surf_triangles[:, 0],\n",
    "    j=surf_triangles[:, 1],\n",
    "    k=surf_triangles[:, 2],\n",
    "    colorscale=\"Viridis\",\n",
    "    autocolorscale=False,\n",
    "    colorbar=dict(\n",
    "        title=dict(\n",
    "            text=\"Displacement (mm)\", side=\"right\", font=dict(size=16, family=\"Arial\")\n",
    "        ),\n",
    "        tickvals=[0, 4, 8, 12],\n",
    "        tickfont=dict(size=14, family=\"Arial\"),\n",
    "        len=0.5,\n",
    "    ),\n",
    "    cmin=0,\n",
    "    cmax=12,\n",
    "    intensity=np.linalg.norm(node_pred, axis=1),\n",
    "    lighting=dict(ambient=1, specular=0, diffuse=0),\n",
    "    opacity=1,\n",
    "    showscale=True,\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[mesh3d])\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        camera=dict(\n",
    "            eye=dict(\n",
    "                x=1,\n",
    "                y=-1,\n",
    "                z=1,\n",
    "            ),\n",
    "            projection=dict(\n",
    "                type=\"orthographic\",\n",
    "            ),\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            nticks=4,\n",
    "            range=[-50, 50],\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            nticks=4,\n",
    "            range=[-50, 50],\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            nticks=4,\n",
    "            range=[0, 60],\n",
    "        ),\n",
    "        aspectmode=\"manual\",\n",
    "        aspectratio=go.layout.scene.Aspectratio(\n",
    "            x=1,\n",
    "            y=1,\n",
    "            z=0.75,\n",
    "        ),\n",
    "    ),\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        b=0,\n",
    "        t=0,\n",
    "        pad=0,\n",
    "    ),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are able to visualize the shape reconstruction of the cylinder with the input motion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion = np.array([8, 8, -1, -0.2, 0.2, 0])\n",
    "\n",
    "motion_tensor = torch.from_numpy((motion - mu[:6]) / std[:6]).float()\n",
    "node_pred = model.forward_with_index(motion_tensor, 0, 2).detach().numpy()\n",
    "node_pred = node_pred * std[12:] + mu[12:]\n",
    "node_pred = node_pred.reshape(-1, 3)\n",
    "node_curr = surf_node.copy()\n",
    "node_curr[:, 1:] += node_pred\n",
    "\n",
    "fig.update_traces(\n",
    "    x=node_curr[:, 1],\n",
    "    y=node_curr[:, 2],\n",
    "    z=node_curr[:, 3],\n",
    "    intensity=np.linalg.norm(node_pred, axis=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have made a real ProSoRo by following the [hardware guide](https://sites.google.com/view/prosoro-hardware), you can use modules in `./modules/` folder to visualize it in an interface. There are three modules provided:\n",
    "\n",
    "- `camera`: capturing the image and estimating the motion of ProSoRo.\n",
    "- `led`: controlling the LED light of the ProSoRo.\n",
    "- `interface`: visualizing the image, motion, force, and shape of the ProSoRo.\n",
    "\n",
    "Start all modules and open the interface in the browser to visualize the ProSoRo. More details can be found in the `./modules/README.md`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
